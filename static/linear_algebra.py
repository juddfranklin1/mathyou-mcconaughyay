LINEAR_ALGEBRA_CONCEPTS = {
    "Eigenvectors and Eigenvalues": {
        "core_idea": "Eigenvectors are the 'special' vectors of a matrix. When a matrix multiplies its eigenvector, the vector doesn't change directionâ€”it only gets stretched or shrunk. The amount it gets stretched by is the 'eigenvalue', $\lambda$. So, for a matrix $A$ and its eigenvector $\vec{v}$, the equation is $A\vec{v} = \lambda\vec{v}$. Eigenvectors reveal the fundamental directions of the transformation the matrix represents.",
        "real_world_application": "Google's original PageRank algorithm used eigenvectors to determine the importance of web pages! It created a huge matrix representing links between pages. The eigenvector corresponding to the largest eigenvalue gave a 'score' for each page's importance. An important page is one that is linked to by other important pages. Eigenvectors literally ranked the internet.",
        "mathematical_demonstration": "Let's check if $\vec{v} = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$ is an eigenvector of the matrix $A = \begin{bmatrix} 3 & 0 \\ 8 & -1 \end{bmatrix}$.<br>1. Multiply the matrix and the vector: $A\vec{v} = \begin{bmatrix} 3 & 0 \\ 8 & -1 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} = \begin{bmatrix} (3)(1)+(0)(2) \\ (8)(1)+(-1)(2) \end{bmatrix} = \begin{bmatrix} 3 \\ 6 \end{bmatrix}$.<br>2. Now, look at the result, $\begin{bmatrix} 3 \\ 6 \end{bmatrix}$. Can we write this as a number (an eigenvalue $\lambda$) times the original vector $\begin{bmatrix} 1 \\ 2 \end{bmatrix}$?<br>Yes! $\begin{bmatrix} 3 \\ 6 \end{bmatrix} = 3 \cdot \begin{bmatrix} 1 \\ 2 \end{bmatrix}$.<br>Since $A\vec{v} = 3\vec{v}$, we've proven that $\vec{v}$ is an eigenvector of A, and its corresponding eigenvalue is $\lambda = 3$. The matrix stretches this vector by a factor of 3!",
        "explanation": "Eigenvectors are vectors that are only scaled by a linear transformation, and eigenvalues are the factors by which they are scaled."
    },
    "Determinants": {
        "core_idea": "The determinant is a single number that tells you a ton about a square matrix. For a 2x2 matrix $\begin{bmatrix} a & b \\ c & d \end{bmatrix}$, the determinant is $ad-bc$. Geometrically, its absolute value tells you the 'scaling factor' of the transformation. If you transform a square of area 1 with the matrix, the new shape (a parallelogram) will have an area equal to $|det(A)|$. If the determinant is 0, the matrix squishes space into a lower dimension (like a line or a point), and it's not invertible!",
        "real_world_application": "In computer graphics, if you're about to apply a transformation matrix to a million-point 3D model, you might calculate the determinant first. If it's zero, you know the transformation will collapse the model flat, which might be a bug. It's a quick check to see if your transformation is 'valid' and reversible.",
        "mathematical_demonstration": "Let's find the determinant of $A = \begin{bmatrix} 4 & 2 \\ 1 & 3 \end{bmatrix}$.<br>1. Identify a, b, c, and d. Here, $a=4, b=2, c=1, d=3$.<br>2. Apply the formula $det(A) = ad - bc$.<br>3. Substitute: $det(A) = (4)(3) - (2)(1) = 12 - 2 = 10$.<br>This tells us two things: 1) The matrix is invertible (since the determinant isn't 0). 2) The transformation scales the area of any shape by a factor of 10.",
        "explanation": "The determinant is a scalar value that can be computed from the elements of a square matrix and encodes certain properties of the linear transformation described by the matrix."
    }
}